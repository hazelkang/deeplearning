{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 기존 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(x, y), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "x = x.astype('float32') \n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x /= 255\n",
    "x_test /= 255\n",
    "\n",
    "y = to_categorical(y, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 36,842\n",
      "Trainable params: 36,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(learning_rate=lr, momentum = momentum):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28, 28)))\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "    model.add(Dense(64, 'relu'))\n",
    "    model.add(Dense(128, 'relu'))\n",
    "    model.add(Dense(units=10, activation='softmax'))\n",
    "    \n",
    "    sgd = SGD(learning_rate=learning_rate, momentum=momentum, nesterov=False)\n",
    "    model.compile(optimizer=sgd, \n",
    "                  loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. schedule 함수 만들기\n",
    "\n",
    "epoch의 값에 따라 learning_rate가 변하는 함수를 만들면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_schedule(epoch, learning_rate=lr):\n",
    "    if epoch < 5:\n",
    "        return lr\n",
    "    else:\n",
    "        return float(lr * tf.math.exp(0.1 * (5- epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule_custom = LearningRateScheduler(my_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "98/98 [==============================] - 2s 19ms/step - accuracy: 0.5039 - loss: 1.3759 - val_accuracy: 0.7420 - val_loss: 0.7189\n",
      "Epoch 2/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.7744 - loss: 0.6341 - val_accuracy: 0.7964 - val_loss: 0.5721\n",
      "Epoch 3/20\n",
      "98/98 [==============================] - 1s 13ms/step - accuracy: 0.8145 - loss: 0.5285 - val_accuracy: 0.8174 - val_loss: 0.5153\n",
      "Epoch 4/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.8308 - loss: 0.4822 - val_accuracy: 0.8266 - val_loss: 0.4873\n",
      "Epoch 5/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.8404 - loss: 0.4556 - val_accuracy: 0.8327 - val_loss: 0.4734\n",
      "Epoch 6/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.8480 - loss: 0.4366 - val_accuracy: 0.8372 - val_loss: 0.4624\n",
      "Epoch 7/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.8536 - loss: 0.4203 - val_accuracy: 0.8393 - val_loss: 0.4511\n",
      "Epoch 8/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.8580 - loss: 0.4086 - val_accuracy: 0.8467 - val_loss: 0.4341\n",
      "Epoch 9/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.8602 - loss: 0.3989 - val_accuracy: 0.8433 - val_loss: 0.4331\n",
      "Epoch 10/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.8626 - loss: 0.3927 - val_accuracy: 0.8393 - val_loss: 0.4440\n",
      "Epoch 11/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.8637 - loss: 0.3862 - val_accuracy: 0.8403 - val_loss: 0.4424\n",
      "Epoch 12/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.8656 - loss: 0.3819 - val_accuracy: 0.8464 - val_loss: 0.4275\n",
      "Epoch 13/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.8669 - loss: 0.3781 - val_accuracy: 0.8525 - val_loss: 0.4131\n",
      "Epoch 14/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.8693 - loss: 0.3739 - val_accuracy: 0.8594 - val_loss: 0.4012\n",
      "Epoch 15/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.8706 - loss: 0.3701 - val_accuracy: 0.8641 - val_loss: 0.3946\n",
      "Epoch 16/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.8719 - loss: 0.3655 - val_accuracy: 0.8651 - val_loss: 0.3920\n",
      "Epoch 17/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.8736 - loss: 0.3614 - val_accuracy: 0.8637 - val_loss: 0.3899\n",
      "Epoch 18/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.8742 - loss: 0.3585 - val_accuracy: 0.8651 - val_loss: 0.3877\n",
      "Epoch 19/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.8753 - loss: 0.3563 - val_accuracy: 0.8662 - val_loss: 0.3858\n",
      "Epoch 20/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.8758 - loss: 0.3545 - val_accuracy: 0.8666 - val_loss: 0.3847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xc8ab79d6d8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.fit(x, y,  epochs = 20, validation_split = 1/6, callbacks = [lr_schedule_custom], batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. tensorflow의 scheduler 사용\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**def** decayed_learning_rate(step):\n",
    "\n",
    "  > return initial_learning_rate * decay_rate ^ (step / decay_steps)\n",
    "  \n",
    "  \n",
    "`decay_steps` 마다 `decay_rate`의 비율로 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler_exp = ExponentialDecay(lr, decay_steps=10000, decay_rate=0.96, staircase=False, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_model(learning_rate=lr, momentum = momentum):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28, 28)))\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "    model.add(Dense(64, 'relu'))\n",
    "    model.add(Dense(128, 'relu'))\n",
    "    model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "98/98 [==============================] - 2s 17ms/step - accuracy: 0.5112 - loss: 1.3768 - val_accuracy: 0.7056 - val_loss: 0.7503\n",
      "Epoch 2/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.7726 - loss: 0.6353 - val_accuracy: 0.7713 - val_loss: 0.6110\n",
      "Epoch 3/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.8128 - loss: 0.5362 - val_accuracy: 0.8195 - val_loss: 0.5147\n",
      "Epoch 4/20\n",
      "98/98 [==============================] - ETA: 0s - accuracy: 0.8299 - loss: 0.48 - 1s 11ms/step - accuracy: 0.8297 - loss: 0.4869 - val_accuracy: 0.8290 - val_loss: 0.4786\n",
      "Epoch 5/20\n",
      "98/98 [==============================] - 1s 11ms/step - accuracy: 0.8396 - loss: 0.4579 - val_accuracy: 0.8266 - val_loss: 0.4751\n",
      "Epoch 6/20\n",
      "98/98 [==============================] - ETA: 0s - accuracy: 0.8448 - loss: 0.44 - 1s 11ms/step - accuracy: 0.8450 - loss: 0.4405 - val_accuracy: 0.8402 - val_loss: 0.4409\n",
      "Epoch 7/20\n",
      "98/98 [==============================] - 1s 11ms/step - accuracy: 0.8522 - loss: 0.4232 - val_accuracy: 0.8271 - val_loss: 0.4818\n",
      "Epoch 8/20\n",
      "98/98 [==============================] - 1s 11ms/step - accuracy: 0.8549 - loss: 0.4155 - val_accuracy: 0.8382 - val_loss: 0.4495\n",
      "Epoch 9/20\n",
      "98/98 [==============================] - 1s 11ms/step - accuracy: 0.8561 - loss: 0.4098 - val_accuracy: 0.8478 - val_loss: 0.4285\n",
      "Epoch 10/20\n",
      "98/98 [==============================] - ETA: 0s - accuracy: 0.8625 - loss: 0.39 - 1s 11ms/step - accuracy: 0.8628 - loss: 0.3936 - val_accuracy: 0.8512 - val_loss: 0.4193\n",
      "Epoch 11/20\n",
      "98/98 [==============================] - 1s 11ms/step - accuracy: 0.8640 - loss: 0.3891 - val_accuracy: 0.8586 - val_loss: 0.4023\n",
      "Epoch 12/20\n",
      "98/98 [==============================] - 1s 11ms/step - accuracy: 0.8686 - loss: 0.3748 - val_accuracy: 0.8567 - val_loss: 0.4050\n",
      "Epoch 13/20\n",
      "98/98 [==============================] - 1s 11ms/step - accuracy: 0.8708 - loss: 0.3691 - val_accuracy: 0.8644 - val_loss: 0.3921\n",
      "Epoch 14/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.8704 - loss: 0.3677 - val_accuracy: 0.8640 - val_loss: 0.3960\n",
      "Epoch 15/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.8741 - loss: 0.3572 - val_accuracy: 0.8560 - val_loss: 0.4116\n",
      "Epoch 16/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.8737 - loss: 0.3555 - val_accuracy: 0.8672 - val_loss: 0.3821\n",
      "Epoch 17/20\n",
      "98/98 [==============================] - ETA: 0s - accuracy: 0.8771 - loss: 0.34 - 1s 12ms/step - accuracy: 0.8767 - loss: 0.3478 - val_accuracy: 0.8675 - val_loss: 0.3807\n",
      "Epoch 18/20\n",
      "98/98 [==============================] - 1s 13ms/step - accuracy: 0.8780 - loss: 0.3468 - val_accuracy: 0.8715 - val_loss: 0.3731\n",
      "Epoch 19/20\n",
      "98/98 [==============================] - 1s 12ms/step - accuracy: 0.8799 - loss: 0.3396 - val_accuracy: 0.8697 - val_loss: 0.3719\n",
      "Epoch 20/20\n",
      "98/98 [==============================] - 1s 11ms/step - accuracy: 0.8814 - loss: 0.3347 - val_accuracy: 0.8694 - val_loss: 0.3733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xc8ac2f6a90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = exp_model()\n",
    "sgd = SGD(learning_rate=lr_scheduler_exp, momentum=momentum, nesterov=False)\n",
    "model.compile(optimizer=sgd, \n",
    "                  loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(x, y,  epochs = 20, validation_split = 1/6, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0066483244>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr(100000) # 0.96^10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ReduceLRonPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plateau: 학습개선이 없는 상태 \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1)\n",
    "\n",
    "#factor: Plateau 상태일때 0.1씩 decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 1s 17us/sample - loss: 1.2686 - accuracy: 0.5666 - val_loss: 0.7005 - val_accuracy: 0.7457\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 1s 11us/sample - loss: 0.6171 - accuracy: 0.7808 - val_loss: 0.5628 - val_accuracy: 0.8001\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 1s 10us/sample - loss: 0.5234 - accuracy: 0.8170 - val_loss: 0.5209 - val_accuracy: 0.8117\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.4818 - accuracy: 0.8311 - val_loss: 0.4966 - val_accuracy: 0.8195\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.4565 - accuracy: 0.8400 - val_loss: 0.4749 - val_accuracy: 0.8283\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4380 - accuracy: 0.8461 - val_loss: 0.4630 - val_accuracy: 0.8348\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.4219 - accuracy: 0.8513 - val_loss: 0.4576 - val_accuracy: 0.8377\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.4091 - accuracy: 0.8555 - val_loss: 0.4428 - val_accuracy: 0.8422\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 1s 11us/sample - loss: 0.3987 - accuracy: 0.8595 - val_loss: 0.4280 - val_accuracy: 0.8499\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 0s 9us/sample - loss: 0.3904 - accuracy: 0.8623 - val_loss: 0.4284 - val_accuracy: 0.8479\n",
      "Epoch 11/20\n",
      "48640/50000 [============================>.] - ETA: 0s - loss: 0.3843 - accuracy: 0.8635\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0006065306719392539.\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.3845 - accuracy: 0.8636 - val_loss: 0.4331 - val_accuracy: 0.8440\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.3796 - accuracy: 0.8654 - val_loss: 0.4279 - val_accuracy: 0.8482\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.3750 - accuracy: 0.8662 - val_loss: 0.4140 - val_accuracy: 0.8496\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.3707 - accuracy: 0.8681 - val_loss: 0.4034 - val_accuracy: 0.8534\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.3668 - accuracy: 0.8694 - val_loss: 0.3913 - val_accuracy: 0.8618\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 1s 11us/sample - loss: 0.3632 - accuracy: 0.8704 - val_loss: 0.3840 - val_accuracy: 0.8642\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 1s 10us/sample - loss: 0.3599 - accuracy: 0.8712 - val_loss: 0.3821 - val_accuracy: 0.8657\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.3563 - accuracy: 0.8729 - val_loss: 0.3823 - val_accuracy: 0.8650\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.3533 - accuracy: 0.8742 - val_loss: 0.3819 - val_accuracy: 0.8650\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 0s 10us/sample - loss: 0.3512 - accuracy: 0.8750 - val_loss: 0.3800 - val_accuracy: 0.8659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24a8e276548>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.fit(x, y,  epochs = 20, validation_split = 1/6, callbacks = [lr_schedule_custom, reduce_lr], batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
